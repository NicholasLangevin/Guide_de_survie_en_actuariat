% Template pour faire aide-mémoire
\documentclass[10pt, french]{article}

%% -----------------------------
%% Préambule
%% -----------------------------
\input{cheatsht-preamble-general.tex}
%% -----------------------------
%% Variable definition
%% -----------------------------
\def\cours{analyse statistique des risques actuariels}
\def\sigle{ACT-2000}
%
% 	Save more space than default
%
\setlength{\abovedisplayskip}{-15pt}
%
%	Extra math symbols
%
\usepackage{mathrsfs}
%
% 	thin space, limits underneath in displays
%
\DeclareMathOperator*{\argmax}{arg\,max} 

%% -----------------------------
%% 	Colour setup for sections
%% -----------------------------
\def\SectionColor{cobalt}
\def\SubSectionColor{azure(colorwheel)}
\def\SubSubSection{azure(colorwheel)}
%% -----------------------------

%% -----------------------------
%% Color definitions
%% -----------------------------
\definecolor{indigo(web)}{rgb}{0.29, 0.0, 0.51}
\definecolor{cobalt}{rgb}{0.0, 0.28, 0.67}
\definecolor{azure(colorwheel)}{rgb}{0.0, 0.5, 1.0}
%% -----------------------------
%% Variable definition
%% -----------------------------
\def\auteur{Alec James van Rassel}
%%
%% Matrix notation variable (bold style)
%%
\newcommand\cololine[2]{\colorlet{temp}{.}\color{#1}\bar{\color{temp}#2}\color{temp}}
\newcommand\colbar[2]{\colorlet{temp}{.}\color{#1}\bar{\color{temp}#2}\color{temp}}

\begin{document}

\begin{multicols*}{2}

\section*{Analyse statistique des risques actuariels}

\subsection*{Vraisemblance}

On peut voir la fonction de densité $f(x; \theta)$ comme étant une fonction du paramètre inconnu $\theta$ avec $x$ fixé; ceci est la fonction de vraisemblance $\mathcal{L}(\theta; x)$.

\subsection*{Qualité de l'estimateur}

La première section traite de \guillemotleft \textbf{estimateurs ponctuels} \guillemotright. 
C'est-à-dire, on produit une seule valeur comme notre meilleur essai pour déterminer la valeur de la population inconnue.
Intrinsèquement, on ne s'attend pas à ce que cette valeur (même si c'en est une bonne) soit la vraie valeur exacte.

Une hypothèse plus utile à des fins d'interprétation est plutôt un \textbf{estimateur par intervalle}; au lieu d'une seule valeur, il retourne un intervalle de valeurs plausibles qui peuvent toutes être la vraie valeur. 
Le type principal d'\textit{estimateur par intervalle} est \textit{l'intervalle de confiance} traité dans la deuxième sous-section.

\subsubsection*{Estimation ponctuelle}

Lorsque nous avons un estimateur $\hat\theta$ pour un paramètre inconnu $\theta$ on espère que, \textbf{en moyenne}, ses erreurs de prévision vont s'annuler.
On peut alors trouver $\text{E}\hat\theta | \theta]$, soit l'espérance de l'estimateur sachant que $\theta$ est la vraie valeur du paramètre.
Par la suite, on calcule son \textbf{biais} $\text{B}(\hat\theta)$ dans la prévision du paramètre:
\begin{algo}{Biais d'un estimateur}
\begin{align*}
	\text{B}(\hat\theta) 
	&= 	\text{E}\hat\theta | \theta] - \theta
\end{align*}
\end{algo}

Cependant, le bais n'indique pas la variabilité de l'estimateur $\hat\theta$ dans sa prévision.
Nous définissons alors la \textbf{borne inférieur Cramèr-Rao} de la variance de l'estimateur $\text{Var}(\hat{\theta})$ avec \textbf{l'information de Fisher} $I(\theta)$:
\begin{algo}{Borne inférieur Cramèr-Rao}
\begin{align*}
	\text{Var}(\hat{\theta}) \ge \frac{1}{n\text{E}\left[\Big(\deriv{\theta}\ln f(x ; \theta)\Big)^{2}\right]}, \quad \text{où } I(\theta) = \text{E}\left[\Big(\deriv{\theta}\ln f(x ; \theta)\Big)^{2}\right]
\end{align*}
\end{algo}

Par la suite, nous pouvons définir \textbf{l'efficacité} d'un estimateur comme étant le ratio de la borne Cramèr-Rao sur la variance de l'estimateur:
\begin{algo}{Efficacité d'un estimateur}
\begin{align*}
	\text{eff}(\theta)
	&=	\frac{\text{Var}(\hat{\theta})^{\text{Rao}}}{\text{Var}(\hat{\theta})} 
	=	\frac{1}{n\text{Var}(\hat{\theta})\text{E}\left[\Big(\deriv{\theta}\ln f(x ; \theta)\Big)^{2}\right]}
\end{align*}
\end{algo}

Si ce ratio est de 1 $\text{eff}(\theta) = 1$, alors l'estimateur est \textbf{efficace}.

Nous pouvons également évaluer si un estimateur est cohérent, ou converge, avec des très grands échantillons; un estimateur $\hat\theta$ est \textbf{consistent} \textit{(angl.)} si la probabilité qu'il diffère de la vraie valeur du paramètre $\theta$ par une erreur $\epsilon$ près de 0 tends vers 0 alors que la taille de l'échantillon $n$ tends vers l'infini:
\begin{algo}{Convergence (\textbf{consistency}) d'un estimateur}
\begin{align*}
	\underset{n \rightarrow \infty}{\lim} \Pr(\big| \hat\theta - \theta \big| > \epsilon) = 0, \quad \epsilon > 0
\end{align*}
\end{algo}

Ce critère peut être rencontré lorsque l'estimateur $\hat\theta$ est \textbf{asymptotiquement sans biais} \textbf{\textit{et}} que la \textbf{variance de l'estimateur} tend vers 0.
En premier temps, on définit ce qu'est un estimateur asymptotiquement sans biais:
\begin{algo}{Estimateur asymptotiquement sans biais}
\begin{align*}
	\underset{n \rightarrow \infty}{\lim} \text{B}(\hat\theta) &= 0
\end{align*}
\end{algo}

Donc si $\underset{n \rightarrow \infty}{\lim} \text{Var}(\hat\theta) = 0$ et que $\underset{n \rightarrow \infty}{\lim} \text{B}(\hat\theta) = 0$ alors l'estimateur est \textbf{consistent}. 
Cependant, l'inverse n'est pas vrai; un estimateur qui est \textbf{consistent} n'implique pas que la variance et le biais tendent vers 0.

Malgré la nature plaisante de la convergence d'un estimateur, beaucoup d'estimateurs ont cette propriété. 
Nous voulons alors une mesure qui n'indique pas seulement qu'un estimateur arrive près de la bonne valeur souvent \textit{(alias, une très petite variance)}, mais qu'il est mieux que d'autres estimateurs.
De plus, dût à la sélection arbitraire de l'erreur $\epsilon$ pour la \textit{consistency} d'un estimateur, il est possible de malicieusement la sélectionner pour faire parler les données comme on le souhaite. 

Nous définissons alors l'\textbf{Erreur Quadratique Moyenne} (EQM), ou \textbf{Mean Squared Error (MSE)}, permettant de comparer les différents estimateurs ayant tous une bonne \textit{consistency} en assurant une cohérence d'interprétation.
\begin{algo}{Erreur Quadratique Moyenne (Mean Squared Error)}
\begin{align*}
	\text{MSE}_{\hat\theta}(\theta)
	&=	\text{E}[(\hat\theta - \theta)^{2} | \theta]
	\Leftrightarrow	\text{Var}(\hat\theta) + \left[\text{B}(\hat\theta)\right]^{2}
\end{align*}
\end{algo}

En combinant tout ces critères, le meilleur estimateur est alors l'estimateur \textbf{sans biais} ayant la \textbf{plus petite variance} possible parmi tous les estimateurs \textit{sans biais} possible; c'est-à-dire, le \textbf{Uniformly Minimum Variance Unbiased Estimator \textit{(UMVUE)}}.

\subsubsection*{Estimation par intervalles}

Un type d'estimateur par intervalle est l'\textbf{intervalle de confiance}:
\begin{algo}{Intervalle de confiance}
Soit le paramètre à estimer $\theta$, alors nous sommes confiant à un niveau de 100$(1 - \alpha)$\% qu'il est contenu entre $(L, U)$. 

De façon équivalente, nous sommes confiant à un seuil de $\alpha$\% qu'il est contenu entre $(L, U)$: 
\begin{equation*}
	\theta \in \left[ L, U\right].
\end{equation*}
Nous pouvons alors dire que $\Pr(L \le \theta \le U) \ge (1 - \alpha)$ pour tout $\theta$.
\end{algo}

Par exemple, dans le cas d'une population avec distribution normale et moyenne $\mu$ inconnue, on a la moyenne échantillonnale $\bar{x}$ (qui est l'estimateur \textit{MVUE}).
\begin{formula}{Intervalle de confiance sur la moyenne \textit{(distribution normale)}} 
Nous sommes confiant à un niveau de 100$(1 - \alpha)$\% que :
\begin{equation*}
	\mu \in \left[ \bar{x} - z_{\alpha/2} \frac{\sigma}{\sqrt{n}}, \bar{x} + z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\right].
\end{equation*}
\end{formula}

%%%
%%%	Méthode du pivot
%%%

\subsection*{Construction d'estimateurs}

Dans la section précédente on évalue les méthodes pour évaluer la \textbf{qualité} de l'estimateur. 
Cependant, comment qu'on obtient des estimateurs pour les évaluer?

Plusieurs méthodes existent pour établir des estimateurs, de plus plusieurs méthodes existent pour estimer des paramètres.
La méthode vu dans le cadre du cours de statistique est la \textbf{méthode fréquentiste}, le cours de mathématiques IARD 1 (ACT-2005) présente \textbf{l'estimation Bayésienne}.

Avant de le faire nous présentons quelques concepts:
\begin{description}
	\item[échantillon aléatoire:] Échantillon d'observations indépendante provenant de la même distribution paramétrique (identiquement distribué); c'est-à-dire, un échantillon \textbf{(iid)}.
	\item[k-ème moment centré à 0:]  $\mu_{k}' = \text{E}[X^{k}]$.
	\item[$100g^{\text{ème}}$ pourcentile:]  $\pi_{g}(\theta) = F^{-1}_{\theta}(g)$.
\end{description}

Les deux premiers estimateurs ci-dessous sont les plus faciles à obtenir, mais sont aussi les moins performants puisqu'ils n'utilisent que quelques traits des données au lieu de l'entièreté des données comme la troisième méthode.

Cette distinction devient particulièrement importante dans le cas d'une distribution avec une queue lourde à la droite (Pareto, Weibull, etc.) où il devient davantage essentiel de connaître les valeurs extrêmes pour bien estimer le paramètre de forme ($\alpha$ pour une Pareto).

Un autre désavantage est que les deux premières méthodes nécessitent que les données proviennent toutes de la même distribution, autrement les moments et quantiles ne seraient pas clairs.

Finalement, sous les deux premières méthodes la décision de quels moments et pourcentiles à utiliser est arbitraire.

\subsubsection*{Méthode des moments (MoM)}

Soit un échantillon aléatoire de taille $n$ (iid), on pose $\hat\mu_{k}' = \mu_{k}'$.
\begin{algo}{Estimation de $\theta$ par la méthode des moments}
L'estimation de $\theta$ est alors toute solution des $p$ équations:
\begin{equation*}
	\mu_{k}'(\theta) = \hat\mu_{k}', \quad	k = 1, 2, \dots, p
\end{equation*}
\end{algo}

La raison pour cet estimateur est que la distribution empirique aura les même $p$ premiers moments centrés à 0 que la distribution paramétrique.

\subsubsection*{Méthode du \guillemotleft Percentile Matching \guillemotright}

Soit un échantillon aléatoire de taille $n$ (iid), on pose $\hat\pi_{g}(\theta) = \pi_{g}(\theta)$.

\begin{algo}{Estimation de $\theta$ par la méthode du \guillemotleft Percentile Matching \guillemotright}
L'estimation de $\theta$ est alors toute solution des $p$ équations:
\begin{equation*}
	F(\hat\pi_{g_{k}} | \theta)	=	g_{k}, \quad	k = 1, 2, \dots, p
\end{equation*}
\end{algo}

La raison pour cet estimateur est que le modèle produit aura $p$ pourcentiles qui vont \guillemotleft matcher \guillemotright les données.

Il peut arriver que les pourcentiles de distributions ne soient pas unique, par exemple dans le cas de données discrètes lorsque le quantile recherché peut tomber entre 2 \emph{marches} de la fonction empirique, ou mal-définis.
Il est alors utile de définir une méthode d'interpolation des quantiles (bien qu'il n'en n'existe pas une officielle définitive).

Soit le \guillemotleft \textbf{smoothed empirical estimate} \guillemotright d'un pourcentile:

\begin{algo}{Smoothed empirical estimate}
On utilise les statistiques d'ordre de l'échantillon $x_{(1)} \le x_{(2)} \le \dots \le x_{(n)}$ pour l'interpolation suivant:
\begin{align*}
	\hat\pi_{g}
	&=	(1 - h)x_{(j)} + h x_{(j + 1)}, \quad \text{ où }	\\
	j
	&=	\lfloor (n + 1) g \rfloor	&
	&\text{ et }	&
	h
	&=	(n + 1) g - j
\end{align*}
\end{algo}


\subsubsection*{Méthode du maximum de vraisemblance}

Nous cherchons à maximiser la probabilité d'observer les données.
Ceci est fait par la vraisemblance $\mathcal{L}(\theta; x)$ ou, puisque le logarithme ne change pas le maximum, la log-vraisemblance $\ell(\theta; x)$ où:

\begin{algo}{Maximum de vraisemblance}
\begin{align*}
	\mathcal{L}(\theta; x)
	&=	\prod_{i = 1}^{n}	f(x_{i}; \theta)	&
	&\text{et}	&
	\ell(\theta; x)
	&=	\sum_{i = 1}^{n} \ln	f(x_{i}; \theta)	&
\end{align*}
et l'\textbf{estimateur du maximum de vraisemblance} de $\bm\theta$ est celui qui maximise la fonction de vraisemblance.
\end{algo}

%%	Propriétés de l'EMV
%%		invariance, convergence, non-biais, Cramèr-Rao, ...

%\subsection*{Autres critères}
%	Quantile-Quantile
%	AIC
%	BIC

%%%
%%%
%%% pas pertinent au cours de stats %%%
%Cependant, il peut être pratique de généraliser cette fonction de vraisemblance pour les cas de données censurées ou tronquées.
%
%Soit un ensemble de données comportant n événements $A_{1}, \dots, A_{n}$ avec $A_{j}$ étant tout ce qui fut observé pour la $j^{\text{e}}$ observation; c'est-à-dire que $A_{j}$ pourrait être une observation unique ou un intervalle (par exemple, dans le cas de données groupées).
%
%De plus, un suppose que $A_{j}$ est une observation de la variable aléatoire $X_{j}$ et que les variables aléatoires $X_{1}, \dots, X_{n}$ ne doivent pas obligatoirement avoir la même distribution paramétrique; cependant, elles doivent tous dépendent du même vecteur paramétrique $\bm\theta$.
%Finalement, comme dans les deux autres cas, les variables aléatoires sont supposées indépendantes.
%
%\begin{align*}
%	\mathcal{L}(\theta; x)
%	&=	\prod_{j = 1}^{n}	\Pr(X_{j} \in A_{j} ; \theta)		
%\end{align*}
%
%Pour faire le lien avec la définition précédente, dans le cas où $A_{j}$ est un point unique et que la distribution est continue $\Pr(X_{j} \in A_{j} | \theta) = f(x_{i}; \theta)$.
%
%\begin{algo}{Données modifiées}
%Pour le cas de données groupées, les observations $c_{0} < c_{1} < \dots < c_{k}$ contiennent $n_{j}$ observations par intervalle $(c_{j - 1}, c_{j}]$, la fonction de vraisemblance est donc:
%\setlength{\mathindent}{-1cm}
%\begin{align*}
%	\mathcal{L}(\theta; x)
%	&=	\prod_{j = 1}^{n}	\left[ F(c_{j}|\theta) - F(c_{j-1}|\theta)\right]^{n_{j}},	\;	\text{données groupées}	\\
%	&=	\prod_{j = 1}^{n}	S(x_{i} ; \theta),	\;	\text{données censurées}	\\
%	&=	\prod_{j = 1}^{n}	\frac{f(x_{i}; \theta)}{S(x_{i} ; \theta)},	\;	\text{données tronquées}
%\end{align*}
%\setlength{\mathindent}{1cm}
%\end{algo}
%%% fin de pas pertinent au cours de stats %%%
%%%
%%%

%%%%%%%%	%%%%	%%%%	%%%%	%%%%	%%%%	%%%%	%%%%	%%%%	
%%%%		À rajouter éventuellement	%%%%	
%%%%%%%%	%%%%	%%%%	%%%%	%%%%	%%%%	%%%%	%%%%	%%%%	

%\subsection*{Tests d'hypothèses}
%%	Contenu à y inclure
%	Hypothèse nulle et alternative
%	Statistique de test
%	Région de réjection
%	Erreurs de type I et II
%		Tests optimaux
%		Lemme de Neymann-Pearson
%		Ratio de vraisemblance
%	Valeurs critique et seuil observé
%	Test unilatéral et bilatéral
%	La valeur p
%	
%	Test uniformément le plus puissant, alias Uniformely Most Powerful (UMP)
%	Tests échantillons normaux
%		Test T
%			Unilatéral (test, taille, puissance, seuil observé, IC)
%			Bilatéral (test, taille, puissance, seuil observé, IC)\\
%		Test sur la variance
%			3 différents problèmes (<=U<, >=U>, =U=/=)
%	Tests grands échantillons
%		Test Z (normal)
%			3 différents problèmes (<=U<, >=U>, =U=/=)
%			(tests, tailles, puissances, seuils observé, IC)
%	Test du Rapport de Vraisemblance
%		Statistique, test
%	Test d'adéquation
%		Fonction de répartition empirique
%		Test de Kolmogorov-Smirnov
%		Test du khi-carré de Pearson
%			design multinomial
%		Tableau de contingence
%		Test d'indépendance du khi-carré


%\subsection*{Distributions d'échantillonnage}
%%	Contenu à y inclure
%	Postulat de normalité
%		Moyenne échantillonnale
%		Variance échantillonnale
%		Statistique T
%		Statistique F
%	Échantillons de distribution inconnue
%		Théorème centrale limite

%\subsection*{Exhaustivité}
%%	Contenu à y inclure
%	Définition de l'exhaustivité
%	Théorème de factorisation de Fisher-Neymann
%	Critère de Lehmann-Scheffé (Exhaustivité minimale)
%	Théorème de factorisation de Fisher-Neymann (cas de plus d'un paramètre)
%	Théorème de Rao-Blackwell
%	MVUE
%		Élaboration sur le MVUE
%		Comment le construire

%%	Statistiques d'ordre
%%	Tableau des intervalles de confiance, tests d'hypothèses, etc. pour des cas spécifiques
%		Variance inconnue, moyenne inconnue pour une normale, proportion, petit échantillon, ...


\end{multicols*}

\end{document}