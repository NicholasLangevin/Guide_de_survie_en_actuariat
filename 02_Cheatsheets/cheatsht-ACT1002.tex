\documentclass[10pt, french]{article}
\usepackage[landscape, hmargin=1cm, vmargin=1.7cm]{geometry}

%% -----------------------------
%% Préambule
%% -----------------------------
\input{cheatsht-preamble-general.tex}
%% -----------------------------
%% Variable definition
%% -----------------------------
%% -----------------------------
%% Footer and header customization
%% -----------------------------
\def\cours{Analyse probabiliste des risques actuariels}
\def\sigle{ACT-1002}
\fancyfoot[R]{\thepage ~de~ \pageref{LastPage}}
\setlist{leftmargin=*}

%% -----------------------------
%% Colour setup for sections
%% -----------------------------
\def\SectionColor{green!50!black}
\def\SubSectionColor{green!20!black}
%% -----------------------------
%% Definition of LaTex math commands
%% -----------------------------
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
%
% Redefine authors
%
\definecolor{burgundy}{rgb}{0.5, 0.0, 0.13}

\begin{document}
\begin{center}
	\textsc{\Large Contributeurs}\\[0.5cm] 
\end{center}
\input{contributeurs/contrib-ACT1002}

\newpage

\raggedcolumns
\begin{multicols*}{3}

\section{Chapitre 1: Analyse combinatoire}
\begin{probch1}{L'analyse combinatoire}
\begin{description}
  \item[Principe de base de comptage :] Pour une expérience 1 avec m résultats possibles et une expérience 2 avec n résultats possibles, il y a m x n possibilités.
  \item[Permutations :] Nombre d'arrangements en tenant compte de l'ordre. La façon de dénombrer les arrangements dépend du type de question.
	  \item[$Exemples$ :] Combien de façons peut-on arranger les chiffres 1, 2, 3 et 4 dans un nombre à 4 chiffres? La réponse est {4!}. La réponse serait la même avec les chiffres 1, 2, 2 et 3, car les deux chiffres 2 ne sont pas considérés comme identiques. 
	  \item[] Toutefois, si on demande combien de façons peut-on distribuer 12 cadeaux différents à 4 personnes, la réponse sera $ 4^{12} $ étant donné que chaque cadeau peut aller à quatre personnes.
	\item[Combinaisons :] Nombre d'arrangements en \textbf{ne} tenant \textbf{pas} compte de l'ordre.
	 \item[$Exemples$ :] En reprenant l'exemple des permutations, mais avec les chiffres 1, 1, 1, 2 et 2, il y aurait 5!/(3!2!) combinaisons puisque les trois 1 et les deux 2 sont considérés identiques.
	 \item[Coefficient binomial :] De l'exemple précédent, on peut observer l'existence du coefficient binomial, qui est défini selon la formule :
	 \begin{align*}
	 \binom{n}{k}
	 &= \frac{n!}{k! \,(n-k)!}
	 \end{align*}
  \item[Coefficient multinomial :] La généralisation du coefficient binomial va comme suit :
  \begin{align*}
  \binom{n}{k_1, k_2, ..., k_m}
  &= \frac{n!}{(k_1)! \, (k_2)! \, ..., (k_m)!}
  \end{align*}
  \item[] Où {$n = \sum_{i = 1}^{m} k_i$}
  \item[Théorème multinomial :] Le coefficient multinomial aide à trouver les coefficients devant les variables lors du développement de multinômes. 
  \begin{itemize}
	  \item Afin de mieux comprendre le théorème multinomial, voici un exemple :
	  	\setlength{\mathindent}{-1cm}
		  \begin{align*}
			(-3x+5y^2)^4 
			&=	\sum_{}^{} \binom{4}{n_1 , n_2} (-3x)^{n_1} (5y^{2})^{n_2}
		  \end{align*}
		\setlength{\mathindent}{1cm}
	 \item Si on cherche le coefficient devant les variables $x^{3}y^{2}$, on remplace $n_1$ par 3 et $n_2$ par 1 et on obtient -540.
\end{itemize} 
\end{description}  
\begin{description}
  \item[Solutions entières non-négatives :] Le nombre de façons dont on peut distribuer un nombre d'objets indissociables dans des «contenants». 
	\begin{itemize}
		\item Il peut y avoir aucun objet dans un «contenant». 
		\item La solution à ce type de problème est donnée par $\binom{n+r-1}{r-1}$ où n est le nombre d'objets et r le nombre de «contenants». 
		\item S'il est mentionné dans le problème qu'il n'est pas nécessaire d'utiliser tous les objets pour les mettre dans les contenants, on peut rajouter un contenant pour les objets «non-utilisés».
	\end{itemize}
  \item[Solutions entières positives:] Le nombre de façons dont on peut distribuer un nombre d'objets indissociables dans des «contenants» et ce, de façon à ce que chaque «contenant» ait au moins un objet. 
  \begin{itemize}
	  \item La solution à ce type de problème est donnée par $\binom{n-1}{r-1}$.
  \end{itemize} 
\end{description}
\end{probch1}

\pagebreak
\section{Chapitre 2: Axiomes de probabilité}
%faut trouver une façon de ramener les colonnes à gaucher comme dans probch1 FC
% effectivement,  pas encore trouvé comment (AJvR)
\begin{rappel}{Domaine et définition}
\begin{description}
	\item[Random Process:]	Famille de variable aléatoires $\{X_{t}: t \in T\}$ qui associe un espace d'états $\Omega$ à un ensemble $S$.
	\begin{enumerate}
		\item[$\Omega$: ] L'espace d'états $\Omega$ est composé des événements possibles de la variable aléatoire $X$.
		\item[] Par exemple, lorsqu'on lance une pièce de monnaie $\Omega = \{\textsf{Face}, \texttt{Pile} \}$.
		\item[$S$: ] L'ensemble $S$ est l'ensemble des probabilités des événements dans $\Omega$.
		\item[] Par exemple, lorsqu'on lance une pièce de monnaie $S = \{\frac{1}{2}, \frac{1}{2} \}$.
	\end{enumerate}
\end{description}
\begin{description}
	\item[iid: ]	Les variables aléatoire $X_{t}$ doivent être indépendantes et identiquement distribuées. Ceci est dénoté par \textit{\textbf{i.i.d.}}.				
	\begin{description}
		\item[indépendant: ] Si $X_{t}$ est une variable aléatoire \textit{iid} alors, pour 2 variables aléatoires $X_{i}$ et $X_{j}$, où $i, j \in T$, le résultat de $X_{i}$ n'a aucun impact sur le résultat de $X_{j}$ pour tout $t \in T$.
		\item[identiquement distribué: ] L'ensemble $S$ est l'ensemble des probabilités des événements dans $\Omega$.
	\end{description}
	\item[Probabilité de $X_{t}$: ]	La probabilité d'un événement $X_{t}$ est dénoté $\Pr(X_{t})$. 
	Ces probabilités forment l'ensemble $S$.
	\begin{description}
		\item[Propriété: ] $\sum_{i = -\infty}^{\infty} \Pr(X_{i}) = 1$
	\end{description}
	\item[Types de variables aléatoire: ]	Il y a 2 types de variables aléatoire, les distributions \textit{discrètes} et \textit{continues}.
		\begin{description}
		\item[Discrète: ]	Si l'ensemble $S$ est dénombrable, c'est-à-dire que $S= \{s\}$, alors la variable aléatoire $X$ est dite \textbf{discrète}.
		\item[Continue: ]	Si l'ensemble $S$ n'est pas dénombrable alors la variable aléatoire $X$ est dite \textbf{continue}.
	\end{description}
\end{description}
\end{rappel}

\begin{probch2}{Concepts et opérations sur les ensembles}
\begin{description} 

%ce serait bien d'avoir des diagrammes de Venn pour des exemples, ce serait plus visuel et surtout moins encombré FC

  \item[L'union ({$\cup$}) :] On peut le définir par un ou. 
  	\begin{itemize}
  	\item	Si l'événement A est d'avoir 3 sur un dé et l'événement B est d'avoir 4 sur ce même dé, les résultats possibles de A{$\cup$}B est 3 et 4.
  	\end{itemize}
  \item[L'intersection ({$\cap$}) :] On peut le définir par un et. 
  	\begin{itemize}
  	\item	Si l'événement A est d'avoir un chiffre pair sur un dé et que l'événement B est d'avoir 5 ou 6 sur ce même lancer de dé, le résultat de $A \cap B$ est 6, car 6 est un nombre pair et fait partie de l'ensemble B. 
  	\end{itemize}
  \item[Complémentaire :] Un événement quelconque est le complémentaire d'un événement A lorsqu'il correspond à tous les résultats de $\Omega$ excluant les résultats de A. 
  	\begin{itemize}
  	\item	Un exemple est l'événement «Avoir un nombre pair sur un dé»; un événement complémentaire serait donc «Avoir un nombre impair sur un dé». 
  	\item	Le complémentaire d'un événement A est désigné par {$\overline{\rm A}$}, $A^{c}$ et $A^{t}$.
  	\end{itemize}
  %C'est quoi le nom des symboles qui suivent, cad la somme d'unions et d'intersections? 
  \item[«Somme d'unions»($\bigcup_{i=1}^{n} A_i$) :] Représentation plus simple et courte de $A_1 \cup A_2 \cup \dots \cup A_n$
  \item[«Somme d'intersections»($\bigcap_{i=1}^{n} A_i$) :] Représentation plus simple et courte de $A_1 \cap A_2 \cap \dots \cap A_n$
  \item[Opérations sur les ensembles :] Les événements peuvent agir à un certain point comme des termes mathématiques, c'est-à-dire qu'on peut effectuer des opérations avec ceux-ci.
  \item[Commutativité :] $A_1	\cup	A_2	=	A_2 \cup A_1$
  \item[] $A_1	\cap	A_2	=	A_2 \cap A_1$
  \item[Associativité :] $(A_1 \cup A_2)	\cup A_3	=	A_1 \cup		(A_2 \cup A_3)$)
  \item[] $(A_1 \cap A_2)	\cap A_3	=	A_1 \cap		(A_2 \cap A_3)$
  \item[Distributivité :] $(A_1 \cup A_2)	\cap A_3 = (A_1 \cap A_3) \cup (A_2 \cap A_3)$
  \item[] $(A_1 \cap A_2)	\cup A_3 = (A_1 \cup A_3) \cap (A_2 \cup A_3)$
  \item[Loi de DeMorgan :] $(\bigcup_{i = 1}^{n} A_{i})^{c} = (\bigcap_{i=1}^{n} A_i^{c})$
  \item[] $(\bigcap_{i = 1}^{n} A_{i})^{c} = (\bigcup_{i=1}^{n} A_i^{c})$
\end{description}
\end{probch2}

\begin{axioms}{Axiomes de probabilité}
\begin{description}
  \item[Définition :] Des axiomes de probabilités sont en quelque sorte des règles, des contraintes ou des formules relatives aux probabilités.
  \item[Exemples :]
  \begin{itemize}
  \item 0 $\le$ Pr(A) $\le$ 1
  \item Pr(S) = 1
  \item Si $A_i$ $\bigcap$ $A_j$ = $\emptyset$ pour i $\neq$ j, alors Pr($\bigcup_{i = 1}^{n}$ $A_i$) = $\sum_{i = 1}^{n}$ Pr($A_i$)
  \end{itemize}
  À partir des axiomes de probabilités, on peut trouver un bon nombre de formules de probabilités. On peut donc dire que les axiomes constitue une base logique de ce que représente les probabilités. On peut déduire par exemple les formules suivantes :
  \begin{itemize}
  \item Pr(E $\cup$ F) = Pr(E) + Pr(F) - Pr(E $\cap$ F)
  \item Pr($E^{c}$) = 1 - Pr(E)
  \end{itemize}
\end{description}
\end{axioms}

\pagebreak
\section{Chapitre 3: Probabilité conditionnelle}
\begin{probch3}{Probabilité conditionnelle}
\begin{description}
	\item[Conditionnel:]	La probabilité que $A$ arrive \textit{sachant} que $B$ est arrivé est: 
	\begin{align*}
		\Pr(A | B) 
		&= 	\frac{\Pr(A \cap B)}{\Pr(B)}	
	\end{align*}
	où la probabilité que $B$ arrive est non-nulle, $\Pr(B) > 0$. Il faut alors s'imaginer qu'en sachant que l'événement B est arrivé, B représente le nouvel ensemble des probabilités S.
	\item[Indépendant:]	Les événements $A$ et $B$ sont indépendant si:
	\begin{equation*}
		\Pr(A \cap B) = \Pr(A) \cdot \Pr(B)
	\end{equation*}
	\item Cette formule est bien sûr aussi bonne pour trois événements indépendants et plus : 
	\setlength{\mathindent}{-1cm}
	\begin{align*}
	\Pr(A_{1} \cap \dots \cap A_{n}) 
	  &= \Pr(A_{1}) \Pr(A_{2}) \dots \Pr(A_{n})
	\end{align*}
\end{description}

Avec la première définition de la probabilité conditionnelle, on peut trouver ces résultats:
\begin{description}
	\item[Relation probabilité conditionnelle: ]	La probabilité que l'événement $E_{2}$ ait lieu sachant que l'événement $E_{1}$ a déjà eu lieu est équivalent à la probabilité que l'événement $E_{1}$ ait lieu sachant que $E_{2}$ a \textit{déjà} eu lieu multiplié par la probabilité que l'événement $E_{2}$ ait lieu peu importe $E_{1}$. \\
	Le tout est encore pondéré par la probabilité que l'événement $E_{1}$ ait lieu peu importe si $E_{2}$ y a.
	\begin{align*}
		\Pr(E_{2} | E_{1})
		&= 	\frac{\Pr(E_{2} \cap E_{1})}{\Pr(E_{1})}		\\
		&=	\frac{\Pr(E_{1} | E_{2}) \Pr(E_{2})}{\Pr(E_{1})}		
	\end{align*}
	\item[Loi des probabilités totales: ]	Les probabilités liées à la variable aléatoire $E$ lorsqu'elles sont conditionnelles à la variable aléatoire discrète $F$ est dénoté comme suit:
	\begin{align*}
		\Pr(E)	&=	\sum_{i = 1}^{n} \Pr(E | F_{i}) \Pr(F_{i})
	\end{align*}
	\item[Formule de Bayes: ]	On combine les deux résultats précédents:
	\begin{align*}
		\Pr(F_{j} | E) 
		&=	\frac{\Pr(E | F_{j}) \cdot \Pr(F_{j})}{\sum_{i = 1}^{n} \Pr(E | F_{i}) \Pr(F_{i})}
	\end{align*}
	Cette formule apparaît surtout dans le genre de problèmes où il y a une inconnue parmi Pr(A|B), Pr(B|A), Pr(A) et Pr(B). Il ne restera alors qu'à isoler la probabilité que l'on cherche.
\end{description}
\end{probch3}



\pagebreak
\section{Chapitre 4: Variable aléatoire discrète}
\begin{probch4}{La variable aléatoire}
  \begin{description}
    \item[Définition :] Nous avons déjà vu que les événements sont délimités par l'ensemble échantillonal S, c'est-à-dire les résultats possibles de l'événement. La variable aléatoire, disons X, sera une fonction de cet ensemble S (S $\in$ $\mathbb{R}$).\\
    Le support, que l'on peut comparer à l'image de la fonction, d'un événement X est composé des résultats possibles d'une expérience, par exemple [0, 1] ou encore un ensemble dénombrable comme \{0, 1/2, 1\}.\\
    Pour bien comprendre la différence entre l'espace échantillonal et le support de X, voici un petit exemple : \\
    On lance une pièce de monnaie deux fois et on définit la variable aléatoire X comme étant le nombre de faces obtenus. L'espace échantillonal de l'expérience est \{(P,P), (P,F), (F,P), (F,F)\} et le support de X est de \{0, 1, 2\}.
	\item [Fonction de masse de probabilité :] La probabilité d'avoir un résultat égal à x. Cette fonction est définie par $\Pr(X = x_i)$ 
	\item[Fonction de répartition ($F_{X} (x)$):] La probabilité d'avoir un résultat inférieur à x.
    \begin{align*}
    F_{X} (x) &= \Pr(X \le x) \\
    &= \sum_{x_{i} \le x}^{} \Pr(X = x_{i})
    \end{align*}
    Pour illustrer la fonction de répartition, on peut s'imaginer un lancer de dé et définir X comme le résultat du lancer. $F_{X} (2)$, par exemple, donnerait alors 1/3 car seuls les résultats 1 et 2 sont considérés sur l'ensemble des 6 possibilités. 
    \item[Propriétés de la fonction de répartition :] La valeur de la fonction de répartition se situe toujours entre 0 et 1, ce qui est logique étant donné que la somme de toutes les probabilités est toujours égale à 1 et qu'il n'existe pas de probabilité inférieure à 0. \\
    La fonction est aussi toujours non-décroissante, car il est impossible de perdre des probabilités alors que les probabilités qui s'ajoutent à mesure que x augmente sont toujours supérieures à 0 (pour une variable aléatoire discrète, cela donne une fonction en escalier à droite).\\
    On sait donc que $F_{X} (a) \le F_{X} (b)$ pour a < b. On peut alors trouver que Pr(a < X $\le$ b) = $F_{X} (b) - F_{X} (a)$.
    \item[Fonction de répartition inverse ($F^{-1}_{X} (u)$):] Aussi nommée la fonction quantile, cette fonction sert à déterminer quel résultat correspond à une quantité u de probabilités accumulées. Par exemple, si je prends un u de 0,5, le résultat sera la médiane. \\
	Cela fonctionne de la façon suivante : on remplace le x de la fonction de répartition par u et cette nouvelle fonction est mise égale à x et on isole le u. Autrement dit, il faut trouver une fonction réciproque. \\
	\item[Espérance :] L'espérance correspond à une moyenne pondéré des probabilités où les pondérations correspondent aux différents valeurs que peut prendre la variable $X$. Elle est définie de la façon suivante: \\
	$$ E[X] = \sum_i x_i * \Pr(X = x_i) $$. L'espérance correspond au résultat espéré lors de l'expérience. Par exemple, l'espérance d'une expérience consistant à lancer un dé serait 3.5. De plus, \\
	il est possible de calculer l'espérance d'une fonction $g(X)$. L'espérance, dans ce cas-ci, est définie de la façon suivante : $E[g(X)] = \sum_i g(x_i) * \Pr(X = x_i) $. \\
	\item[Propriétés de l'espérance: ] L'espérance est un opérateur linéaire. Ainsi, $E[2x^2+6x+5]$ peut se réécrire, une fois simplifiée, $2E[X^2]+6E[X]+5$. Aussi, si $g(x) \le h(x)$, $\forall x$, alors $E[g(x)] \le E[h(h)]$. \\
	\item[Variance :] La variance est une mesure de dispersion qui se trouve à être la moyenne du carrée des écarts entre x et sa moyenne. La variance est définie de la façon suivante : $ Var(X) = E[(X - E[X])^2]$. En développant cette \\ 
	expression, on retrouve l'expression davantage utilisée en probabilité, soit $Var(X) = E[X^2] - (E[X])^2$.  Afin de calculer la variance on trouve habituellement le premier et le deuxième moment de X et on remplace dans la formule. \\
	De plus, la variance n'est pas un opérateur linéaire. Cependant, $Var(aX + b) = a^2 Var(X)$ où $a$ et $b$ sont des constantes réelles.
\end{description}
\end{probch4}
\end{multicols*}

\end{document}
